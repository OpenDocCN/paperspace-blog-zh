# 具有梯度的端到端推荐系统——第六部分:结论和下一步

> 原文:[https://blog . paper space . com/end-to-end-end-recommender-system-part-6-end-next-steps/](https://blog.paperspace.com/end-to-end-recommender-system-part-6-conclusion-next-steps/)

## 第 6 部分介绍

在这个六部分系列的最后一部分，我们回顾了系列的要点，并指出下一步的工作，既针对这项工作的梯度可以做的其他事情，也针对希望了解更多的读者。

### 系列零件

[第 1 部分:提出业务问题](https://blog.paperspace.com/end-to-end-recommender-system-part-1-business-problem/)
[第 2 部分:准备数据](https://blog.paperspace.com/end-to-end-recommender-system-part-2-data-preparation/)
[第 3 部分:构建张量流模型](https://blog.paperspace.com/end-to-end-recommender-system-part-3-building-tensorflow-model/)
[第 4 部分:调整模型以获得最佳性能](https://blog.paperspace.com/end-to-end-recommender-system-part-4-tuning-model-best-performance/)
[第 5 部分:将模型部署到生产中](https://blog.paperspace.com/end-to-end-recommender-system-part-5-deploying-model-production/)
[**第 6 部分:总结、结论和后续步骤**](https://blog.paperspace.com/end-to-end-recommender-system-part-6-conclusion-next-steps/)

### 伴随材料

*   本博客系列附带资料的主要位置是位于[https://github.com/gradient-ai/Deep-Learning-Recommender-TF](https://github.com/gradient-ai/Deep-Learning-Recommender-TF)的 GitHub 资源库。
*   其中包含项目的笔记本`deep_learning_recommender_tf.ipynb`，可以在渐变笔记本或 JupyterLab 界面中运行，以及渐变工作流的 3 个文件:`workflow_train_model.py`、`workflow-train-model.yaml`和`workflow-deploy-model.yaml`。
*   回购的目的是能够被使用和遵循，而不必参考博客系列，反之亦然，但它们相互补充。

### 注意

公共集群上的 Gradient 产品和工作流中的模型部署支持目前正处于待定状态，预计将于 2021 年第四季度推出。因此，笔记本`deep_learning_recommender_tf.ipynb`中关于模型部署的第 5 部分已显示，但尚未运行。

* * *

## 讨论

正如我们在第 1 部分中看到的，我们打算展示这个系列的各种亮点。概括一下这些:

1.  演示一个现实世界风格的机器学习的例子
2.  将端到端数据流与梯度笔记本电脑和工作流程相结合
3.  使用基于 Gradient 与 Git 集成的现代数据科学方法
4.  使用 TensorFlow 2 和 TensorFlow 推荐器(TFRS)来训练包括深度学习的推荐器模型
5.  使用反映真实项目变量和现实的训练数据
6.  使用完整的 TensorFlow 子类化 API 构建自定义模型
7.  显示改善结果的工作超参数调整
8.  使用梯度部署及其 TensorFlow 服务集成的部署模型
9.  包括一个独立的工作 Jupyter 笔记本和 Git 存储库
10.  让它与广泛的受众相关，包括 ML 工程师、数据科学家以及介于两者之间的人

我们现在可以添加一些讨论和进一步的评论。

很多网上资料显示 ML 却忽略工程，或者显示工程却忽略 ML。

换句话说，一个复杂的模型可能被训练，但我们不知道如何部署它，或者一个新的工程设置可能被显示，但只是在玩具模型或数据上。

在这两种情况下，像数据准备和模型调整这样的基本要素也经常被忽略。这使得想要做真实事情的用户缺少工作示例。

因为 Gradient 横跨数据科学实验和生产(笔记本和工作流)，并且旨在用于真实端到端问题的数据科学，所以我们希望展示这两个领域，而不是跳过它们，同时避免系列变得太长。

企业中的数据科学仍然是一个不断发展的领域。

最佳实践在不断变化。数据科学家有时比软件工程师具有更差的软件工程技能，并且软件工程师可能正在生产包含他们不完全理解的分析的模型。在笔记本电脑上工作的数据科学家和试图将其转化为生产部署的工程师之间的差异就是例证。

事实是，数据科学从根本上来说是迭代的，Gradient 等工具可以帮助数据科学家和 ML 工程师在共享环境中迭代，这是实现共享目标的重要条件。

TensorFlow 2 (TF2)比 TensorFlow 1 好用得多。许多在线材料，如教程、博客、堆栈溢出，仍然是版本 1，或者没有区分。梯度材料的大部分也是如此，因为它比 TF2 存在的时间更长。所以我们认为在这里开始展示 TF2 的实质性例子以及它如何应用于梯度是很重要的。

TensorFlow 推荐器(TFRS)是对 TensorFlow 的扩展，它添加了一些类，使构建一流的推荐器变得更加容易。在写这篇文章的时候，它还是 0.4 版本。但它看起来令人印象深刻，非常适合我们在这里使用它的任务。

子类化 API 很好地展示了出来，因为现实世界的业务问题通常有一些必需的定制组件，这些组件是更简单的高级顺序和功能 ML 接口(如 AutoML 或无代码工具)无法表达的。因此，通过在这里显示子类化 API，它演示了梯度设置如何可以用于解决实际问题的完全通用的分析。

部署模型并不容易。

这方面的一个例子是，在撰写本文时，8 个 TFRS 教程并没有显示一个工作的生产部署。

这是有原因的。他们模型的教学设置意味着他们被安排来清楚地展示他们是如何工作的，而不是被部署。它们确实以某种形式显示了返回的预测，但清楚地显示生产部署将是一个理想的补充。我们在本系列中展示了这样的部署，这对于我们来说更容易，因为 Gradient 已经有了必要的基础设施、容器和计算硬件来完成它。所以我们所要做的就是适当地重写模型类。

附带的笔记本大致跟随博客，但并不完全对应其所有部分。该笔记本被设计为独立的，所以你不需要在它和这个博客之间来回翻转来使用它。希望这种设置对那些也看笔记本的读者来说效果不错。

## 结论

我们的业务问题被表述为:

> 证明 Paperspace 渐变笔记本和工作流可用于解决真实的机器学习问题。通过展示从原始数据到生产部署的端到端解决方案来做到这一点。进一步表明所演示的内容可以构建成一个完整的企业级系统。在这种情况下，该模型是一个推荐系统，其结果通过利用经过调整的深度学习组件来改进。

我们已经表明，添加了调整的深度学习的推荐器将预测和真实用户评级之间的均方根误差从 1.11 提高到 1.06。进一步改进的主要方法是添加推荐系统架构的其他元素，例如交叉特征。

Gradient 将数据科学家的用户友好型和分析友好型工作方式与工程师的坚实 MLOps 基础相结合。我们展示了笔记本电脑和工作流的使用如何有助于有效的端到端数据科学项目。

感谢阅读！

## 后续步骤

在这里，我们讨论了如果工作要扩展，项目的一些后续步骤。它们大致按照在数据流中遇到的顺序排列。

作为读者，接下来的步骤是在[项目 GitHub 资源库](https://github.com/gradient-ai/Deep-Learning-Recommender-TF)中试用笔记本，或者点击下面的链接。

#### 数据科学和推荐者

这些后续步骤是由一些一般的数据科学考虑推动的，并且更具体地针对推荐者和这个项目。

#### 商业故事

我们从谈论业务问题开始，但最终没有扩展到成功的用户评级预测之外。当然，这里我们的实际目的是“证明纸空间梯度可以用于解决真正的机器学习问题”，但它可以显示，例如，数据科学指标如何转换为业务指标，并进而显示这些指标是否满足量化目标并增加价值。

#### 探索性数据分析

第 2 部分解决了一些与数据相关的问题，比如特性和目标没有被区分，但是也提到了在一个完整的项目中要做的各种进一步的探索。下一步将是绘制诸如训练集中用户评级的分布图。我们还可以发现其他潜在的错误值、意外的分布等等。然后，可以将它们与测试集的输出进行比较，并形成监控模型漂移的基础之一。

#### 数据清理

数据中的错误值或缺失值可以采取多种形式，如`Inf`、`NaN`、`0`、`9999.9`、超出范围等。，并且通常只能通过使用领域知识和与提供数据的人的通信来完全定位。在电影数据中，电影和 id 不匹配、重复、错别字、分级错误等。，也可能存在。对于这种数据，一些算法比其他算法更健壮，但是通常对于 ML，更好的数据准备将给出更好的结果。

#### 大数据

这个术语现在已经有点过时了，但是作者最喜欢的定义是“数据的大小打破了你最喜欢的分析工具。”推荐系统可能会访问包含数百万用户和内容项的数据，从而产生比电影镜头大得多的数据集。展示如何在梯度生态系统中处理此类数据，用于培训和部署(流)，将是有价值的。

#### 特征工程

利用推荐器的深度学习组件，可以使用比例如矩阵分解中更丰富的特征。这里要添加的一个明显的例子是将时间戳特征化为一天中的时间、一周中的日期等。，但也有更复杂的方法，如 TFRS 教程中显示的特征交叉。

#### 超参数调谐

笔记本显示了在几个学习率上的基本超参数网格搜索。这足以说明如何通过梯度笔记本和工作流程来处理它们。其他常见参数，如层大小、层数、优化器、激活函数、正则化和网络架构，可以得到更充分的探讨。

将所有这些写成循环会变得很笨拙，所以通过环境变量传递参数，或者使用 Keras tuner 或 TensorBoard HParams 的某种组合会给出更好的搜索。

类似地，某种形式的智能参数搜索或 AutoML 可以给出比定义自己的超参数网格更好的结果。

#### 添加检索模型

我们的项目显示了排名模型，因此可以添加相应的检索模型。包含两者的组合模型也是可能的。

#### 更复杂的推荐器

TFRS 教程显示了各种比检索和排序更复杂的模型，包括组合的检索和排序模型，以及实现上述特征交叉的深度交叉网络(DCN)。DCNs 倾向于使用更少的参数给出同样好的建议。由于我们已经在使用和部署模型的通用子类化 API 形式，所有这些都可以添加到我们的项目中。

#### 冷启动问题

对于推荐者来说，冷启动问题在这里表现为向还没有看过任何电影并且因此没有给出评级的新用户推荐什么。通过引入新用户，这可以在部署期间得到明确解决。

#### 多样化

仅推荐与用户已经观看过的非常相似的电影可能是过于限制性的，因为他们可能不想观看更多相同的电影。推荐太不一样的电影也没有用，因为他们不会想看那些。推荐的内容和用户已经观看的内容之间的差异或变化量是可以调整的。与许多产品调整一样，指导这一点的一个好方法是具体说明什么业务指标是最大化的，并通过 A/B 测试确定什么工作得好。

#### 大规模部署，高性能

这里，我们展示了几行示例数据，这些数据是从一个已经存在的字典格式传递到部署的模型的。更好的方法是采用一种可能在生产系统中传递的格式，例如由公司的上游堆栈处理的表单，该堆栈处理传入的用户活动，但从 ML 的角度来看仍然是原始的。

因为推荐很可能需要实时提供，所以数据流比批处理要好。TFRS 展示了一个性能增强的例子，其中 ScaNN 近似最近邻库用于加速邻居计算，从而加速系统的检索模型部分。

#### 转换字节编码的数据

我们避开了将字节编码的电影数据转换成 JSON 的问题，只使用样本行发送到已经作为字典给出的模型。如果进入生产部署的新电影数据是字节编码的，并且需要转换，这当然必须解决。

#### 词汇外(OOV)课程

模型部署需要对训练集中不存在的数据具有鲁棒性，例如错误的格式、数值数据的越界值或分类数据的新的未知类。特别是对于像电影这样的东西，新的看不见的类，比如新的电影，可能最终会被提供给已部署的模型。除了拒绝不符合所有标准的行之外，TensorFlow 还能够通过将这些类分配给一个或多个 OOV 类占位符来处理这些类，这可以显示出来。

#### 输出

这里我们看到输出看起来没问题。正如所料，它们是 0 到 5 之间的数字。然而，可能的情况是，通过简单地将大多数预测指定为大约 3.5 的模型已经实现了最佳均方误差。因此，探索预测并将其与训练集进行比较将是非常重要的。

#### 再现性

由于 Gradient 的设置包括 Git 存储库、模型版本、容器和 YAML 工作流规范，推荐器模型训练和给定数据的结果应该是可再现的。

在实践中，TensorFlow 和神经网络有大量的数据选择、参数和随机种子，它们都各不相同，此外，在分布式系统中，不能保证文件行的顺序。因此，精确的再现性可能是不可能的，但仍然可以表明结果在统计上是可再现的——例如，如果误差线是使用一些合理的方法从评级中得出的，那么同一版本数据流的未来实例在这些误差范围内应该是一致的。

#### 解释和说明

众所周知，各种行业都有法规要求来说明“为什么”一个模型做出某种预测，并且一些算法比其他算法更容易解释。深度学习是更困难的方法之一，但模型不可知的方法，如 SHAP，可以显示出来。此外，它们必须适合推荐者，而不是常规的监督学习。

#### 公平/偏见

随着模型影响到我们日常生活的更多方面，它们变得越来越重要。虽然电影推荐可能不是这方面最重要的例子，但推荐者仍有可能被改变以促进某些内容或抑制其他内容。例如，显示推荐的电影范围公平地反映了存在的内容，并且在推荐中不存在依赖于例如用户人口统计的歧视性特征的偏见，这将是有用的。

#### 迁移学习

机器学习可能是计算密集型的，特别是深度学习可能需要大量的计算时间和训练数据才能给出最佳结果。虽然 Gradient 旨在使您可以轻松地将 GPU 和分布式计算添加到您的设置中，但尽可能减少计算负担是有意义的。

现在越来越普遍的一种方法是迁移学习，在这种方法中，基于基本信息(如图像的常见成分)训练的网络可以用作训练更具体内容的起点，而不是从头开始训练网络。迁移学习常用于计算机视觉和自然语言处理。

#### 模型监控

监控分为应用程序状态——例如模型是否正在运行、正常运行时间、吞吐量延迟等。、以及数据科学状态，例如输出的敏感性、概念漂移、数据漂移或模型漂移。

由于用于比较模型输出的基本事实标签通常不可用，或者可能稍后才可用，因此需要基于输入和输出数据来监控性能。因此，应用程序监控可以通过查询 Gradient 对 Prometheus 数据库的后端使用情况来显示。

各种数据科学指标，如训练集中的评级分布和输出数据中的评级分布之间的“距离”，可以通过与现有监控工具的集成来导出。监控的关键点是模型在一个 API 端点上，所以它正在做的事情可以被任何可以看到它的工具访问。

#### 模型应用程序

虽然本博客系列的读者和 Gradient 的用户很可能是技术人员，但该模型的结果及其商业价值可以通过一个可以看到其端点的应用程序(如 Streamlit)向非技术人员开放。

## 链接和延伸阅读

### 图纸空间

[主站点](https://www.paperspace.com)
[AI wiki](https://docs.paperspace.com/machine-learning)
[博客](https://blog.paperspace.com/)
[商业资源](https://resources.paperspace.com)
[社区](https://community.paperspace.com)
[联系销售](https://info.paperspace.com/contact-sales)
[核心，我们的云基础设施](https://www.paperspace.com/core)
[脸书](https://www.facebook.com/HelloPaperspace)
[GitHub](https://github.com/Paperspace)
[帮助中心](https://support.paperspace.com)
[学习](https://learn.paperspace.com)

### 梯度

[主站点](https://gradient.paperspace.com)
[API 引用](https://paperspace.github.io/gradient-cli)
[高级技术组](https://gradient.paperspace.com/atg)
[文档](https://docs.paperspace.com)
[机器学习展示](https://ml-showcase.paperspace.com)
[公共数据集](https://docs.paperspace.com/gradient/data/public-datasets-repository)

### 推荐者和 TensorFlow

Paperspace 是 TensorFlow 的服务合作伙伴，也与 fast.ai、Nvidia 和其他公司合作。本系列中的代码部分基于 TensorFlow 推荐器教程。

[谷歌推荐课程](https://developers.google.com/machine-learning/recommendation)
[现代推荐系统](https://towardsdatascience.com/modern-recommender-systems-a0c727609aa8)
[英伟达梅林](https://developer.nvidia.com/nvidia-merlin)

[tensor flow](https://www.tensorflow.org)
[tensor flow Python API](https://www.tensorflow.org/api_docs/python)
[tensor flow 推荐器](https://www.tensorflow.org/recommenders)